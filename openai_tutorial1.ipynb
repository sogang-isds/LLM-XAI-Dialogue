{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# OpenAI API 및 LangChain 사용하기\n",
    "\n",
    "## OpenAI API"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-06-02T14:49:47.797245Z",
     "start_time": "2023-06-02T14:49:45.687910Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in /Users/lifefeel/PythonVirtualEnv/XAI_Law/lib/python3.10/site-packages (0.27.7)\r\n",
      "Requirement already satisfied: requests>=2.20 in /Users/lifefeel/PythonVirtualEnv/XAI_Law/lib/python3.10/site-packages (from openai) (2.31.0)\r\n",
      "Requirement already satisfied: tqdm in /Users/lifefeel/PythonVirtualEnv/XAI_Law/lib/python3.10/site-packages (from openai) (4.65.0)\r\n",
      "Requirement already satisfied: aiohttp in /Users/lifefeel/PythonVirtualEnv/XAI_Law/lib/python3.10/site-packages (from openai) (3.8.4)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/lifefeel/PythonVirtualEnv/XAI_Law/lib/python3.10/site-packages (from requests>=2.20->openai) (3.1.0)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/lifefeel/PythonVirtualEnv/XAI_Law/lib/python3.10/site-packages (from requests>=2.20->openai) (3.4)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/lifefeel/PythonVirtualEnv/XAI_Law/lib/python3.10/site-packages (from requests>=2.20->openai) (2.0.2)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/lifefeel/PythonVirtualEnv/XAI_Law/lib/python3.10/site-packages (from requests>=2.20->openai) (2023.5.7)\r\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/lifefeel/PythonVirtualEnv/XAI_Law/lib/python3.10/site-packages (from aiohttp->openai) (23.1.0)\r\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/lifefeel/PythonVirtualEnv/XAI_Law/lib/python3.10/site-packages (from aiohttp->openai) (6.0.4)\r\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /Users/lifefeel/PythonVirtualEnv/XAI_Law/lib/python3.10/site-packages (from aiohttp->openai) (4.0.2)\r\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/lifefeel/PythonVirtualEnv/XAI_Law/lib/python3.10/site-packages (from aiohttp->openai) (1.9.2)\r\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/lifefeel/PythonVirtualEnv/XAI_Law/lib/python3.10/site-packages (from aiohttp->openai) (1.3.3)\r\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/lifefeel/PythonVirtualEnv/XAI_Law/lib/python3.10/site-packages (from aiohttp->openai) (1.3.1)\r\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"\" # 환경변수에 OPENAI_API_KEY를 설정합니다."
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-03T09:08:33.509353Z",
     "start_time": "2023-06-03T09:08:33.495990Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Text Completion 예제\n",
    "\n",
    "기본적인 텍스트 생성 예제입니다."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "import openai\n",
    "\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\") # 환경변수에서 OPENAI_API_KEY를 가져와 openai.api_key에 할당합니다.\n",
    "\n",
    "response = openai.Completion.create(\n",
    "  model=\"text-davinci-003\", # 사용할 AI 모델을 지정합니다. 여기서는 \"text-davinci-003\" 모델을 사용하였습니다.\n",
    "  prompt=\"안녕? 넌 누구니?\", # AI 모델에게 전달할 프롬프트를 지정합니다.\n",
    "  max_tokens=256, # 생성될 텍스트의 최대 토큰 수를 지정합니다. 여기서는 256개의 토큰을 지정하였습니다.\n",
    "  temperature=0 # 출력의 다양성을 조절합니다. 값이 0이면 가장 확률이 높은 텍스트를 생성하고, 값이 1에 가까울수록 더 다양한 텍스트를 생성합니다.\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-02T14:51:06.669655Z",
     "start_time": "2023-06-02T14:51:00.524529Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"finish_reason\": \"stop\",\n",
      "      \"index\": 0,\n",
      "      \"logprobs\": null,\n",
      "      \"text\": \"\\n\\n\\uc548\\ub155\\ud558\\uc138\\uc694. \\ub098\\ub294 \\ud64d\\uae38\\ub3d9\\uc774\\uc5d0\\uc694.\"\n",
      "    }\n",
      "  ],\n",
      "  \"created\": 1685717462,\n",
      "  \"id\": \"cmpl-7N0PGYOflVLhSFt451lHa9mGBkbfu\",\n",
      "  \"model\": \"text-davinci-003\",\n",
      "  \"object\": \"text_completion\",\n",
      "  \"usage\": {\n",
      "    \"completion_tokens\": 42,\n",
      "    \"prompt_tokens\": 19,\n",
      "    \"total_tokens\": 61\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-02T14:51:08.023324Z",
     "start_time": "2023-06-02T14:51:08.019315Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "안녕하세요. 나는 홍길동이에요.\n"
     ]
    }
   ],
   "source": [
    "print(response.choices[0].text)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-02T14:51:48.519847Z",
     "start_time": "2023-06-02T14:51:48.516826Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Chat Completion 예제"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "example_messages = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"안녕? 넌 누구니?\",\n",
    "    },\n",
    "]\n",
    "\n",
    "response = openai.ChatCompletion.create(\n",
    "  model=\"gpt-3.5-turbo\", # 사용할 AI 모델을 지정합니다. 여기서는 \"text-davinci-003\" 모델을 사용하였습니다.\n",
    "  messages=example_messages, # AI 모델에게 전달할 프롬프트를 지정합니다.\n",
    "  max_tokens=256, # 생성될 텍스트의 최대 토큰 수를 지정합니다. 여기서는 256개의 토큰을 지정하였습니다.\n",
    "  temperature=0 # 출력의 다양성을 조절합니다. 값이 0이면 가장 확률이 높은 텍스트를 생성하고, 값이 1에 가까울수록 더 다양한 텍스트를 생성합니다.\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-02T15:18:55.243689Z",
     "start_time": "2023-06-02T15:18:50.018152Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"finish_reason\": \"stop\",\n",
      "      \"index\": 0,\n",
      "      \"message\": {\n",
      "        \"content\": \"\\uc548\\ub155\\ud558\\uc138\\uc694! \\uc800\\ub294 OpenAI\\uc758 \\uc778\\uacf5\\uc9c0\\ub2a5 \\uc5b4\\uc2dc\\uc2a4\\ud134\\ud2b8\\uc785\\ub2c8\\ub2e4. \\ubb34\\uc5c7\\uc744 \\ub3c4\\uc640\\ub4dc\\ub9b4\\uae4c\\uc694?\",\n",
      "        \"role\": \"assistant\"\n",
      "      }\n",
      "    }\n",
      "  ],\n",
      "  \"created\": 1685719130,\n",
      "  \"id\": \"chatcmpl-7N0qAhpv5bWgayjZIBTkWhtdkH1Op\",\n",
      "  \"model\": \"gpt-3.5-turbo-0301\",\n",
      "  \"object\": \"chat.completion\",\n",
      "  \"usage\": {\n",
      "    \"completion_tokens\": 39,\n",
      "    \"prompt_tokens\": 21,\n",
      "    \"total_tokens\": 60\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-02T15:18:56.132441Z",
     "start_time": "2023-06-02T15:18:56.128577Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "안녕하세요! 저는 OpenAI의 인공지능 어시스턴트입니다. 무엇을 도와드릴까요?\n"
     ]
    }
   ],
   "source": [
    "print(response.choices[0].message.content)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-02T15:18:58.231624Z",
     "start_time": "2023-06-02T15:18:58.229964Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### role을 지정하여 대화하기\n",
    "\n",
    "role 종류\n",
    "- system: 시스템의 목적을 정의할 때 사용\n",
    "- assistant: assistant의 응답 메시지를 저장하는데 사용\n",
    "- user: 사용자의 입력을 넘길 때 사용\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "outputs": [],
   "source": [
    "example_messages = [\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": \"You are a helpful assistant that like google assistant or siri.\"\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"안녕? 넌 누구니?\",\n",
    "    },\n",
    "]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-02T16:17:48.932729Z",
     "start_time": "2023-06-02T16:17:48.929007Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "안녕하세요! 저는 인공지능 기반의 개인 비서로, 여러분의 질문에 대답하고 도움을 드리기 위해 만들어졌습니다. 무엇을 도와드릴까요?\n"
     ]
    }
   ],
   "source": [
    "response = openai.ChatCompletion.create(\n",
    "  model=\"gpt-3.5-turbo\", # 사용할 AI 모델을 지정합니다. 여기서는 \"text-davinci-003\" 모델을 사용하였습니다.\n",
    "  messages=example_messages, # AI 모델에게 전달할 프롬프트를 지정합니다.\n",
    "  max_tokens=256, # 생성될 텍스트의 최대 토큰 수를 지정합니다. 여기서는 256개의 토큰을 지정하였습니다.\n",
    "  temperature=0 # 출력의 다양성을 조절합니다. 값이 0이면 가장 확률이 높은 텍스트를 생성하고, 값이 1에 가까울수록 더 다양한 텍스트를 생성합니다.\n",
    ")\n",
    "\n",
    "response_message_1 = response.choices[0].message.content\n",
    "print(response_message_1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-02T16:22:24.251090Z",
     "start_time": "2023-06-02T16:22:14.138954Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 대화를 이어나가기\n",
    "\n",
    "이전에 받은 대화를 assistant의 입력으로 사용하여 대화를 이어나갈 수 있습니다."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'content': 'You are a helpful assistant that like google assistant or siri.',\n",
      "  'role': 'system'},\n",
      " {'content': '안녕? 넌 누구니?', 'role': 'user'},\n",
      " {'content': '안녕하세요! 저는 인공지능 기반의 개인 비서로, 여러분의 질문에 대답하고 도움을 드리기 위해 만들어졌습니다. 무엇을 '\n",
      "             '도와드릴까요?',\n",
      "  'role': 'assistant'},\n",
      " {'content': '2020년 올림픽은 개최국은 어디야?', 'role': 'user'}]\n"
     ]
    }
   ],
   "source": [
    "next_messages = [\n",
    "    {\n",
    "        \"role\": \"assistant\",\n",
    "        \"content\": response_message_1,\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"2020년 올림픽은 개최국은 어디야?\",\n",
    "    },\n",
    "]\n",
    "\n",
    "new_messages = example_messages.copy()\n",
    "new_messages.extend(next_messages)\n",
    "from pprint import pprint\n",
    "pprint(new_messages)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-02T16:23:59.380035Z",
     "start_time": "2023-06-02T16:23:59.375745Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020년 올림픽은 일본의 도쿄에서 개최됩니다.\n"
     ]
    }
   ],
   "source": [
    "response = openai.ChatCompletion.create(\n",
    "  model=\"gpt-3.5-turbo\", # 사용할 AI 모델을 지정합니다. 여기서는 \"text-davinci-003\" 모델을 사용하였습니다.\n",
    "  messages=new_messages, # AI 모델에게 전달할 프롬프트를 지정합니다.\n",
    "  max_tokens=256, # 생성될 텍스트의 최대 토큰 수를 지정합니다. 여기서는 256개의 토큰을 지정하였습니다.\n",
    "  temperature=0 # 출력의 다양성을 조절합니다. 값이 0이면 가장 확률이 높은 텍스트를 생성하고, 값이 1에 가까울수록 더 다양한 텍스트를 생성합니다.\n",
    ")\n",
    "response_message_2 = response.choices[0].message.content\n",
    "print(response_message_2)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-02T16:23:17.933212Z",
     "start_time": "2023-06-02T16:23:14.038507Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 대화의 맥락을 유지하는지 확인하기\n",
    "\n",
    "이전 대화 맥락을 고려하여 답변을 하고 있는지 확인하기 위해 짧은 입력만 주고 대답을 받아봅니다."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'content': 'You are a helpful assistant that like google assistant or siri.',\n",
      "  'role': 'system'},\n",
      " {'content': '안녕? 넌 누구니?', 'role': 'user'},\n",
      " {'content': '안녕하세요! 저는 인공지능 기반의 개인 비서로, 여러분의 질문에 대답하고 도움을 드리기 위해 만들어졌습니다. 무엇을 '\n",
      "             '도와드릴까요?',\n",
      "  'role': 'assistant'},\n",
      " {'content': '2020년 올림픽은 개최국은 어디야?', 'role': 'user'},\n",
      " {'content': '2020년 올림픽은 일본의 도쿄에서 개최됩니다.', 'role': 'assistant'},\n",
      " {'content': '언제 열려?', 'role': 'user'}]\n"
     ]
    }
   ],
   "source": [
    "next_messages = [\n",
    "    {\n",
    "        \"role\": \"assistant\",\n",
    "        \"content\": response_message_2,\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"언제 열려?\",\n",
    "    },\n",
    "]\n",
    "\n",
    "new_messages.extend(next_messages)\n",
    "pprint(new_messages)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-02T16:24:01.612874Z",
     "start_time": "2023-06-02T16:24:01.609027Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020년 도쿄 올림픽은 2021년 7월 23일부터 8월 8일까지 열릴 예정입니다.\n"
     ]
    }
   ],
   "source": [
    "response = openai.ChatCompletion.create(\n",
    "  model=\"gpt-3.5-turbo\", # 사용할 AI 모델을 지정합니다. 여기서는 \"text-davinci-003\" 모델을 사용하였습니다.\n",
    "  messages=new_messages, # AI 모델에게 전달할 프롬프트를 지정합니다.\n",
    "  max_tokens=256, # 생성될 텍스트의 최대 토큰 수를 지정합니다. 여기서는 256개의 토큰을 지정하였습니다.\n",
    "  temperature=0 # 출력의 다양성을 조절합니다. 값이 0이면 가장 확률이 높은 텍스트를 생성하고, 값이 1에 가까울수록 더 다양한 텍스트를 생성합니다.\n",
    ")\n",
    "response_message_3 = response.choices[0].message.content\n",
    "print(response_message_3)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-02T16:24:29.176220Z",
     "start_time": "2023-06-02T16:24:21.219314Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## LangChain"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in /Users/lifefeel/PythonVirtualEnv/XAI_Law/lib/python3.10/site-packages (0.0.188)\r\n",
      "Requirement already satisfied: PyYAML>=5.4.1 in /Users/lifefeel/PythonVirtualEnv/XAI_Law/lib/python3.10/site-packages (from langchain) (6.0)\r\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /Users/lifefeel/PythonVirtualEnv/XAI_Law/lib/python3.10/site-packages (from langchain) (2.0.15)\r\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /Users/lifefeel/PythonVirtualEnv/XAI_Law/lib/python3.10/site-packages (from langchain) (3.8.4)\r\n",
      "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /Users/lifefeel/PythonVirtualEnv/XAI_Law/lib/python3.10/site-packages (from langchain) (4.0.2)\r\n",
      "Requirement already satisfied: dataclasses-json<0.6.0,>=0.5.7 in /Users/lifefeel/PythonVirtualEnv/XAI_Law/lib/python3.10/site-packages (from langchain) (0.5.7)\r\n",
      "Requirement already satisfied: numexpr<3.0.0,>=2.8.4 in /Users/lifefeel/PythonVirtualEnv/XAI_Law/lib/python3.10/site-packages (from langchain) (2.8.4)\r\n",
      "Requirement already satisfied: numpy<2,>=1 in /Users/lifefeel/PythonVirtualEnv/XAI_Law/lib/python3.10/site-packages (from langchain) (1.24.3)\r\n",
      "Requirement already satisfied: openapi-schema-pydantic<2.0,>=1.2 in /Users/lifefeel/PythonVirtualEnv/XAI_Law/lib/python3.10/site-packages (from langchain) (1.2.4)\r\n",
      "Requirement already satisfied: pydantic<2,>=1 in /Users/lifefeel/PythonVirtualEnv/XAI_Law/lib/python3.10/site-packages (from langchain) (1.10.8)\r\n",
      "Requirement already satisfied: requests<3,>=2 in /Users/lifefeel/PythonVirtualEnv/XAI_Law/lib/python3.10/site-packages (from langchain) (2.31.0)\r\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /Users/lifefeel/PythonVirtualEnv/XAI_Law/lib/python3.10/site-packages (from langchain) (8.2.2)\r\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/lifefeel/PythonVirtualEnv/XAI_Law/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.1.0)\r\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /Users/lifefeel/PythonVirtualEnv/XAI_Law/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (3.1.0)\r\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/lifefeel/PythonVirtualEnv/XAI_Law/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.4)\r\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/lifefeel/PythonVirtualEnv/XAI_Law/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.2)\r\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/lifefeel/PythonVirtualEnv/XAI_Law/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.3)\r\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/lifefeel/PythonVirtualEnv/XAI_Law/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\r\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.3.0 in /Users/lifefeel/PythonVirtualEnv/XAI_Law/lib/python3.10/site-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain) (3.19.0)\r\n",
      "Requirement already satisfied: marshmallow-enum<2.0.0,>=1.5.1 in /Users/lifefeel/PythonVirtualEnv/XAI_Law/lib/python3.10/site-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain) (1.5.1)\r\n",
      "Requirement already satisfied: typing-inspect>=0.4.0 in /Users/lifefeel/PythonVirtualEnv/XAI_Law/lib/python3.10/site-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain) (0.9.0)\r\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in /Users/lifefeel/PythonVirtualEnv/XAI_Law/lib/python3.10/site-packages (from pydantic<2,>=1->langchain) (4.6.2)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/lifefeel/PythonVirtualEnv/XAI_Law/lib/python3.10/site-packages (from requests<3,>=2->langchain) (3.4)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/lifefeel/PythonVirtualEnv/XAI_Law/lib/python3.10/site-packages (from requests<3,>=2->langchain) (2.0.2)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/lifefeel/PythonVirtualEnv/XAI_Law/lib/python3.10/site-packages (from requests<3,>=2->langchain) (2023.5.7)\r\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /Users/lifefeel/PythonVirtualEnv/XAI_Law/lib/python3.10/site-packages (from SQLAlchemy<3,>=1.4->langchain) (2.0.2)\r\n",
      "Requirement already satisfied: packaging>=17.0 in /Users/lifefeel/PythonVirtualEnv/XAI_Law/lib/python3.10/site-packages (from marshmallow<4.0.0,>=3.3.0->dataclasses-json<0.6.0,>=0.5.7->langchain) (23.1)\r\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /Users/lifefeel/PythonVirtualEnv/XAI_Law/lib/python3.10/site-packages (from typing-inspect>=0.4.0->dataclasses-json<0.6.0,>=0.5.7->langchain) (1.0.0)\r\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install langchain"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-02T15:39:05.402314Z",
     "start_time": "2023-06-02T15:39:03.380897Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Chat 모델 사용하기"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.schema import (\n",
    "    AIMessage,\n",
    "    HumanMessage,\n",
    "    SystemMessage\n",
    ")\n",
    "\n",
    "chat_llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0.0)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-03T09:08:44.828031Z",
     "start_time": "2023-06-03T09:08:44.774579Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 단순 대화하기\n",
    "\n",
    "메시지는 HumanMessage를 이용해 생성합니다. 이 메시지를 chat_llm에 전달하면 AI 모델이 답변을 생성합니다.\n",
    "OpenAI API를 직접 사용하는 것과 마찬가지로, 질의를 보낼 때마다 새로운 세션으로 동작합니다."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "안녕하세요! 저는 OpenAI의 인공지능 어시스턴트입니다. 무엇을 도와드릴까요?\n"
     ]
    }
   ],
   "source": [
    "result = chat_llm([HumanMessage(content=\"안녕? 넌 누구니?\")])\n",
    "print(result.content)\n",
    "result_content_1 = result.content"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-02T16:53:38.527162Z",
     "start_time": "2023-06-02T16:53:33.506554Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020년 서울의 인구는 약 9,736,962명입니다.\n"
     ]
    }
   ],
   "source": [
    "result = chat_llm([HumanMessage(content=\"2020년 서울의 인구를 알려줘\")])\n",
    "print(result.content)\n",
    "result_content_2 = result.content"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-02T16:53:48.406994Z",
     "start_time": "2023-06-02T16:53:45.057775Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "부산은 대한민국의 도시 중 하나로, 경제, 문화, 교통 등 다양한 측면에서 중요한 역할을 합니다. 부산은 대한민국의 대표적인 항구 도시로서, 국내외 무역과 관광 산업 등에 큰 기여를 하고 있습니다. 또한 부산은 해운대, 광안리, 송정 등의 해변과 부산타워, 용두산 등의 관광 명소가 많아 관광객들에게 인기 있는 도시입니다.\n"
     ]
    }
   ],
   "source": [
    "result = chat_llm([HumanMessage(content=\"그럼 부산은?\")])\n",
    "print(result.content)\n",
    "result_content_3 = result.content"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-02T16:54:10.353016Z",
     "start_time": "2023-06-02T16:53:49.959976Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 대화의 이력을 통해 대화하기\n",
    "\n",
    "위와 동일한 대화를 보내 맥락을 잘 유지하고 답변을 하는지 확인합니다."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "outputs": [],
   "source": [
    "chat_messages = [\n",
    "    SystemMessage(content=\"You are a helpful assistant that like google assistant or siri.\"),\n",
    "    HumanMessage(content=\"안녕? 넌 누구니?\"),\n",
    "    AIMessage(content=result_content_1),\n",
    "    HumanMessage(content=\"2020년 서울의 인구를 알려줘\"),\n",
    "    AIMessage(content=result_content_2),\n",
    "    HumanMessage(content=\"그럼 부산은?\"),\n",
    "    AIMessage(content=result_content_3),\n",
    "]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-02T16:54:17.583749Z",
     "start_time": "2023-06-02T16:54:17.577755Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "하지만, 제가 말씀드리고자 하는 것은 부산의 인구입니다. 2020년 기준 부산의 인구는 약 3,367,957명입니다.\n"
     ]
    }
   ],
   "source": [
    "result = chat_llm(chat_messages)\n",
    "print(result.content)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-02T16:54:25.583403Z",
     "start_time": "2023-06-02T16:54:18.482034Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 토큰 수 확인하기"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "outputs": [
    {
     "data": {
      "text/plain": "13"
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_llm.get_num_tokens('안녕? 넌 누구니?')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-02T17:47:26.472406Z",
     "start_time": "2023-06-02T17:47:26.464909Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "outputs": [
    {
     "data": {
      "text/plain": "305"
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_llm.get_num_tokens_from_messages(chat_messages)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-02T17:38:38.458657Z",
     "start_time": "2023-06-02T17:38:38.194542Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Batch 단위로 메시지 보내기"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "batch_messages = [\n",
    "    [\n",
    "        SystemMessage(content=\"You are a helpful assistant that like google assistant or siri.\"),\n",
    "        HumanMessage(content=\"2020년 서울의 인구를 알려줘\")\n",
    "    ],\n",
    "    [\n",
    "        SystemMessage(content=\"You are a helpful assistant that like google assistant or siri.\"),\n",
    "        HumanMessage(content=\"그럼 부산은?\")\n",
    "    ]\n",
    "]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-03T07:53:18.380895Z",
     "start_time": "2023-06-03T07:53:18.374444Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generations=[[ChatGeneration(text='2020년 12월 31일 기준으로 서울특별시의 총 인구는 약 9,736,962명입니다.', generation_info=None, message=AIMessage(content='2020년 12월 31일 기준으로 서울특별시의 총 인구는 약 9,736,962명입니다.', additional_kwargs={}, example=False))], [ChatGeneration(text='부산은 대한민국의 도시 중 하나로, 경상남도에 위치해 있습니다. 부산은 대한민국에서 가장 큰 항구도시이며, 경제적으로 중요한 역할을 합니다. 또한, 부산은 해변과 산이 어우러져 자연경관이 아름다운 도시로도 유명합니다.', generation_info=None, message=AIMessage(content='부산은 대한민국의 도시 중 하나로, 경상남도에 위치해 있습니다. 부산은 대한민국에서 가장 큰 항구도시이며, 경제적으로 중요한 역할을 합니다. 또한, 부산은 해변과 산이 어우러져 자연경관이 아름다운 도시로도 유명합니다.', additional_kwargs={}, example=False))]] llm_output={'token_usage': {'prompt_tokens': 76, 'completion_tokens': 149, 'total_tokens': 225}, 'model_name': 'gpt-3.5-turbo'}\n"
     ]
    }
   ],
   "source": [
    "result = chat_llm.generate(batch_messages)\n",
    "\n",
    "print(result)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-03T07:53:33.842128Z",
     "start_time": "2023-06-03T07:53:19.085536Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### 생성 결과를 출력"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch index: 0, response message: 2020년 12월 31일 기준으로 서울특별시의 총 인구는 약 9,736,962명입니다.\n",
      "batch index: 1, response message: 부산은 대한민국의 도시 중 하나로, 경상남도에 위치해 있습니다. 부산은 대한민국에서 가장 큰 항구도시이며, 경제적으로 중요한 역할을 합니다. 또한, 부산은 해변과 산이 어우러져 자연경관이 아름다운 도시로도 유명합니다.\n"
     ]
    }
   ],
   "source": [
    "for idx, generation in enumerate(result.generations):\n",
    "    print(f'batch index: {idx}, response message: {generation[0].text}')\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-03T07:56:41.491419Z",
     "start_time": "2023-06-03T07:56:41.486322Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### 토큰 사용량 출력"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'token_usage': {'prompt_tokens': 76, 'completion_tokens': 149, 'total_tokens': 225}, 'model_name': 'gpt-3.5-turbo'}\n"
     ]
    }
   ],
   "source": [
    "print(result.llm_output)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-03T07:56:50.801532Z",
     "start_time": "2023-06-03T07:56:50.795684Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 스트리밍 요청"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verse 1:\n",
      "Bubbles rising to the top\n",
      "A refreshing drink that never stops\n",
      "Clear and crisp, it's oh so pure\n",
      "Sparkling water, I can't ignore\n",
      "\n",
      "Chorus:\n",
      "Sparkling water, oh how you shine\n",
      "A taste so clean, it's simply divine\n",
      "You quench my thirst, you make me feel alive\n",
      "Sparkling water, you're my favorite vibe\n",
      "\n",
      "Verse 2:\n",
      "No sugar, no calories, just H2O\n",
      "A drink that's good for me, don't you know\n",
      "With lemon or lime, it's even better\n",
      "Sparkling water, you're my forever\n",
      "\n",
      "Chorus:\n",
      "Sparkling water, oh how you shine\n",
      "A taste so clean, it's simply divine\n",
      "You quench my thirst, you make me feel alive\n",
      "Sparkling water, you're my favorite vibe\n",
      "\n",
      "Bridge:\n",
      "I'll never get tired of your effervescence\n",
      "You're the perfect drink for any occasion\n",
      "Whether I'm at home or out on the town\n",
      "Sparkling water, you never let me down\n",
      "\n",
      "Chorus:\n",
      "Sparkling water, oh how you shine\n",
      "A taste so clean, it's simply divine\n",
      "You quench my thirst, you make me feel alive\n",
      "Sparkling water, you're my favorite vibe\n",
      "\n",
      "Outro:\n",
      "Sparkling water, you're the one for me\n",
      "A drink that's always refreshing and free\n",
      "I'll never give you up, you're my go-to\n",
      "Sparkling water, I love you."
     ]
    }
   ],
   "source": [
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
    "\n",
    "chat = ChatOpenAI(streaming=True, callbacks=[StreamingStdOutCallbackHandler()], temperature=0)\n",
    "resp = chat([HumanMessage(content=\"Write me a song about sparkling water.\")])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-03T09:29:21.258696Z",
     "start_time": "2023-06-03T09:28:54.270803Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Chat Prompt Template 사용하기"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "from langchain.prompts.chat import (\n",
    "    ChatPromptTemplate,\n",
    "    SystemMessagePromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    ")\n",
    "\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "chat_llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0.0)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-03T07:59:23.824298Z",
     "start_time": "2023-06-03T07:59:23.816897Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [
    "template = \"You are a helpful assistant that translates {input_language} to {output_language}.\"\n",
    "system_message_prompt = SystemMessagePromptTemplate.from_template(template)\n",
    "\n",
    "human_template = \"{text}\"\n",
    "human_message_prompt = HumanMessagePromptTemplate.from_template(human_template)\n",
    "\n",
    "chat_prompt = ChatPromptTemplate.from_messages([system_message_prompt, human_message_prompt])\n",
    "\n",
    "# get a chat completion from the formatted messages\n",
    "response = chat_llm(chat_prompt.format_prompt(input_language=\"English\", output_language=\"Korean\", text=\"I love programming.\").to_messages())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-03T08:19:24.241590Z",
     "start_time": "2023-06-03T08:19:22.511641Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[AIMessage(content='저는 프로그래밍을 좋아합니다.', additional_kwargs={}, example=False)]\n",
      "content: 저는 프로그래밍을 좋아합니다.\n"
     ]
    }
   ],
   "source": [
    "print([response])  # 객체를 출력하기 위해 리스트 형태로 감쌈\n",
    "print('content:', response.content)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-03T08:20:59.663960Z",
     "start_time": "2023-06-03T08:20:59.655721Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Chain 사용하기\n",
    "\n",
    "#### LLM과 prompt 템플릿를 함께 사용하기\n",
    "\n",
    "위와 동일한 대화를 `LLMChain`를 이용해 생성합니다. `PromptTemplate` 객체를 `to_messages()`로 변환하는 과정이 필요 없이 바로 `LLMChain`에 넘기면 됩니다. 응답 결과는 객체가 아닌 텍스트인 부분이 다릅니다."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [],
   "source": [
    "from langchain import LLMChain\n",
    "\n",
    "llm_chain = LLMChain(llm=chat_llm, prompt=chat_prompt)\n",
    "response = llm_chain.run(input_language=\"English\", output_language=\"Korean\", text=\"I love programming.\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-03T08:40:51.270820Z",
     "start_time": "2023-06-03T08:40:48.622173Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "저는 프로그래밍을 좋아합니다.\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-03T08:40:52.870693Z",
     "start_time": "2023-06-03T08:40:52.861604Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 수학 계산용 체인 - LLMMathChain"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001B[1m> Entering new LLMMathChain chain...\u001B[0m\n",
      "What is 2 raised to the 10 power?\u001B[32;1m\u001B[1;3m```text\n",
      "2**10\n",
      "```\n",
      "...numexpr.evaluate(\"2**10\")...\n",
      "\u001B[0m\n",
      "Answer: \u001B[33;1m\u001B[1;3m1024\u001B[0m\n",
      "\u001B[1m> Finished chain.\u001B[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": "'Answer: 1024'"
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain import LLMMathChain\n",
    "\n",
    "math_chain = LLMMathChain.from_llm(llm=chat_llm, verbose=True)\n",
    "\n",
    "math_chain.run(\"What is 2 raised to the 10 power?\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-03T08:42:49.339330Z",
     "start_time": "2023-06-03T08:42:47.113921Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 대화용 체인 - ConversationChain\n",
    "\n",
    "대화용 체인은 local memory 객체에 대화의 이력을 저장하고 관리한다. 이전에 수동으로 이력을 관리하던 방식과 달리, 이력을 관리하는 부분을 자동으로 처리한다."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001B[1m> Entering new ConversationChain chain...\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "Human: 안녕? 넌 누구니?\n",
      "AI:\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": "'안녕하세요! 저는 인공지능입니다. 제 이름은 OpenAI GPT-3입니다. 저는 대화를 하고, 질문에 답하며, 정보를 제공하는 데에 사용됩니다. 무엇을 도와드릴까요?'"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain import ConversationChain\n",
    "\n",
    "conversation_chain = ConversationChain(llm=chat_llm, verbose=True)\n",
    "conversation_chain.predict(input=\"안녕? 넌 누구니?\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-03T09:19:04.248749Z",
     "start_time": "2023-06-03T09:18:55.710817Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001B[1m> Entering new ConversationChain chain...\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: 안녕? 넌 누구니?\n",
      "AI: 안녕하세요! 저는 인공지능입니다. 제 이름은 OpenAI GPT-3입니다. 저는 대화를 하고, 질문에 답하며, 정보를 제공하는 데에 사용됩니다. 무엇을 도와드릴까요?\n",
      "Human: 2020년 서울의 인구를 알려줘\n",
      "AI:\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": "'2020년 서울의 인구는 약 9,736,962명입니다. 이는 2019년 대비 약 0.2% 증가한 수치입니다. 서울은 대한민국의 수도이며, 인구 밀도가 매우 높은 도시 중 하나입니다. 서울은 경제, 문화, 교육 등 다양한 분야에서 중요한 역할을 합니다.'"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation_chain.predict(input=\"2020년 서울의 인구를 알려줘\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-03T09:19:18.680110Z",
     "start_time": "2023-06-03T09:19:07.483070Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001B[1m> Entering new ConversationChain chain...\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: 안녕? 넌 누구니?\n",
      "AI: 안녕하세요! 저는 인공지능입니다. 제 이름은 OpenAI GPT-3입니다. 저는 대화를 하고, 질문에 답하며, 정보를 제공하는 데에 사용됩니다. 무엇을 도와드릴까요?\n",
      "Human: 2020년 서울의 인구를 알려줘\n",
      "AI: 2020년 서울의 인구는 약 9,736,962명입니다. 이는 2019년 대비 약 0.2% 증가한 수치입니다. 서울은 대한민국의 수도이며, 인구 밀도가 매우 높은 도시 중 하나입니다. 서울은 경제, 문화, 교육 등 다양한 분야에서 중요한 역할을 합니다.\n",
      "Human: 그럼 부산은?\n",
      "AI:\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": "'2020년 부산의 인구는 약 3,398,361명입니다. 이는 2019년 대비 약 0.1% 감소한 수치입니다. 부산은 대한민국의 대표적인 항구도시이며, 경제적으로 중요한 역할을 합니다. 또한 부산은 해운대, 광안리 등의 해변과 부산타워, 용두산 등의 관광지로도 유명합니다.'"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation_chain.predict(input=\"그럼 부산은?\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-03T09:19:45.239896Z",
     "start_time": "2023-06-03T09:19:31.853426Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Few shot 에제\n",
    "\n",
    "HumanMessage와 AIMessage를 이용해 대화를 반복하여 incontext learning을 위한 예시를 넘길 수 있습니다."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "from langchain import LLMChain\n",
    "from langchain.prompts.chat import (\n",
    "    ChatPromptTemplate,\n",
    "    SystemMessagePromptTemplate,\n",
    "    AIMessagePromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-03T10:05:57.462595Z",
     "start_time": "2023-06-03T10:05:57.456171Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "template = \"You are a helpful assistant that translates english to pirate.\"\n",
    "system_message_prompt = SystemMessagePromptTemplate.from_template(template)\n",
    "example_human = HumanMessagePromptTemplate.from_template(\"Hi\")\n",
    "example_ai = AIMessagePromptTemplate.from_template(\"Argh me mateys\")\n",
    "human_template=\"{text}\"\n",
    "human_message_prompt = HumanMessagePromptTemplate.from_template(human_template)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-03T10:05:58.081086Z",
     "start_time": "2023-06-03T10:05:58.074037Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "data": {
      "text/plain": "\"I be lovin' programmin', me hearty!\""
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_prompt = ChatPromptTemplate.from_messages([system_message_prompt, example_human, example_ai, human_message_prompt])\n",
    "chain = LLMChain(llm=chat_llm, prompt=chat_prompt)\n",
    "# get a chat completion from the formatted messages\n",
    "chain.run(text=\"I love programming.\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-03T10:07:57.145019Z",
     "start_time": "2023-06-03T10:07:55.677998Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
